{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "Python 3.7.7 64-bit ('pytorch_deeplearning': conda)",
      "display_name": "Python 3.7.7 64-bit ('pytorch_deeplearning': conda)",
      "metadata": {
        "interpreter": {
          "hash": "2bcd7ec7ba57b04cf90fee3838748171677195bfc714753350d4adb3113cc5c7"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7-final"
    },
    "colab": {
      "name": "vgg16.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaara-dev/brain-tumor/blob/main/vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KC1F1tnDERU"
      },
      "source": [
        "import time\n",
        "import platform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms, utils, models\n",
        "from torch.utils.data import Dataset, DataLoader ,Subset\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", module=\"matplotlib\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hVq_9zzE7eA"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "FOLDERNAME = 'project_test'\n",
        "ASSIGNMENTNAME = 'vgg16.ipynb'\n",
        "\n",
        "%cd drive/My\\ Drive\n",
        "%cp -r $FOLDERNAME/$ASSIGNMENTNAME ../../\n",
        "%cd ../../\n",
        "#use gpu if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TX9xTF65xp_"
      },
      "source": [
        "# To test your code change the following paths so they point to samples on your drives.\n",
        "# Once you finish testing you code, revert the changes and write back these paths.\n",
        "PATH_TUMOR_Folder = 'drive/MyDrive/project_test/TUMOR_TEST' \n",
        "PATH_NOTUMOR_Folder ='drive/MyDrive/project_test/NOTUMOR_TEST'\n",
        "\n",
        "#Path of the training data with one directory\n",
        "PATH_Folder_Train = 'drive/MyDrive/project_test/ALLDATA_TRAIN'\n",
        "\n",
        "# Resize the images to the size expected by your model.\n",
        "dataset_yes_test = ImageFolder(PATH_TUMOR_Folder, transform=Compose([Resize((224, 224)),ToTensor()]))\n",
        "dataset_no_test = ImageFolder(PATH_NOTUMOR_Folder, transform=Compose([Resize((224, 224)),ToTensor()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwCxTlOmDXg-"
      },
      "source": [
        "##########\n",
        "#this function gets data batch of images and labels and plots 30 images with the label above\n",
        "def PlotImages(images, labels):\n",
        "  with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    #plt.figure.tight_layout()\n",
        "    figure = plt.figure(figsize=(18, 6))\n",
        "    cols, rows = 3, 10\n",
        "    for i in range(1,len(images)):\n",
        "\n",
        "      figure.add_subplot(cols,rows, i)\n",
        "    \n",
        "      plt.title(labels[i].numpy())\n",
        "      plt.axis(\"off\")\n",
        "      \n",
        "      plt.imshow(np.transpose(images[i].detach().numpy(), (1, 2, 0)),cmap=plt.get_cmap('gist_gray') ,)\n",
        "      \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8hNgle2DERc"
      },
      "source": [
        "# training data, just for plotting:\n",
        "train_path=PATH_Folder_Train\n",
        "validation_path='drive/MyDrive/project_test/ALLDATA_VALDATION/'\n",
        "nepochs =60\n",
        "batch_size =30\n",
        "num_workers = 2\n",
        "learningRate =0.0001\n",
        "image_size = (224,224)\n",
        "#generate dataset with compose image in tensor format:\n",
        "dataset=torchvision.datasets.ImageFolder(\n",
        "    root=train_path,\n",
        "    transform=transforms.Compose([\n",
        "    transforms.Resize(image_size),    \n",
        "    transforms.ToTensor()\n",
        "]))\n",
        "#load data\n",
        "dataset_loader=torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "next(iter(dataset_loader))\n",
        "data =next(iter(dataset_loader))\n",
        "images, labels = data\n",
        "PlotImages(images, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAuRWvPeDERd"
      },
      "source": [
        "#normalization of images to match VGG image format\n",
        "data_transforms=transforms.Compose([\n",
        "    transforms.Resize(image_size)\n",
        "    ,transforms.ToTensor()\n",
        "    ,transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-jJqn6rDERe"
      },
      "source": [
        "#generate two datasets (one for training and one for validation)\n",
        "train_data=torchvision.datasets.ImageFolder(\n",
        "    root=train_path,\n",
        "    transform=data_transforms\n",
        ")\n",
        "validation_data=torchvision.datasets.ImageFolder(\n",
        "    root=validation_path,\n",
        "    transform=data_transforms\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi2-WxkkDERe"
      },
      "source": [
        "#load data to data loader, training and validation\n",
        "train_loader=torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "validation_loader=torch.utils.data.DataLoader(\n",
        "    validation_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        "\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "i55JuvpjDERe"
      },
      "source": [
        "print(\"Classes : \", train_data.class_to_idx)\n",
        "print(\"Number of Training Samples : \", len(train_data))\n",
        "print(\"Number of Validation Samples : \", len(validation_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "whikDFlHDERg"
      },
      "source": [
        "#plot training batch\n",
        "batch = next(iter(train_loader))\n",
        "images, labels = batch\n",
        "\n",
        "PlotImages(images, labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "M1Y_a6XcDERi"
      },
      "source": [
        "# load trained model vgg16\n",
        "model = models.vgg16(pretrained=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "BX5-7uYkDERj"
      },
      "source": [
        "#print current model parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "non_trainable_params = total_params - total_trainable_params\n",
        "print('Total Parameters: ',total_params)\n",
        "print('Total Trainable Parameters: ',total_trainable_params)\n",
        "print('Total Non Trainable Parameters: ',non_trainable_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "ZoS2FNr3DERk"
      },
      "source": [
        "for param in model.features.parameters():\n",
        "    param.requires_grad=False\n",
        "#define layers relation\n",
        "gap = nn.AdaptiveAvgPool2d((1, 1))\n",
        "first_fc_layer=nn.Linear(512, 1024)\n",
        "second_fc_layer=nn.Linear(1024, 1024)\n",
        "last_fc_layer=nn.Linear(1024, 2)\n",
        "do1=torch.nn.Dropout(p=0, inplace=False)\n",
        "do2=torch.nn.Dropout(p=0, inplace=False)\n",
        "#assign to existing model layers\n",
        "model.avgpool = gap\n",
        "model.classifier[0]=first_fc_layer\n",
        "model.classifier[3]=second_fc_layer\n",
        "model.classifier[6]=last_fc_layer\n",
        "model.classifier[2]=do1\n",
        "model.classifier[5]=do2\n",
        "\n",
        "#use gpu if possible\n",
        "model.to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "1X0X3QhjDERl"
      },
      "source": [
        "#print updated model parameters \n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "non_trainable_params = total_params - total_trainable_params\n",
        "print('Total Parameters: ',total_params)\n",
        "print('Total Trainable Parameters: ',total_trainable_params)\n",
        "print('Total Non Trainable Parameters: ',non_trainable_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hydemIr6DERl"
      },
      "source": [
        "#define criterion to avoid overfitting\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "#optimizes model learning taking into consideration learning rate and model parameters\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=learningRate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEDEnCKP06rg"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OArU5VFgDERn"
      },
      "source": [
        "##################\n",
        "#this function gets loss history, validation loss_history ,corrects history ,validation corrects history\n",
        "#and plots loss/accuracy\n",
        "def PlotLossAccuracy( loss_history  ,val_loss_history ,corrects_history ,val_corrects_history):\n",
        "  plt.style.use('seaborn-darkgrid')\n",
        "  plt.figure()\n",
        "  plt.plot(loss_history, color = 'red')\n",
        "  plt.plot(val_loss_history, color = 'darkgreen')\n",
        "  plt.plot(corrects_history, color = 'magenta')\n",
        "  plt.plot(val_corrects_history, color = 'blue')\n",
        "  plt.title('Model Loss/Accuracy')\n",
        "  plt.ylabel('Loss/Accuracy')\n",
        "  plt.xlabel('Epoch #')\n",
        "  plt.legend(['Training loss', 'Validation loss', 'Training accuracy', 'Validation accuracy'], loc='center right')\n",
        "  plt.grid(axis = 'y', c = 'black', alpha = 0.2)\n",
        "  plt.grid(axis = 'x', c = 'black', alpha = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1SYJ6nTDERo"
      },
      "source": [
        "########################\n",
        "#this function gets corrects history, validation corrects history and plots the modes accuracy\n",
        "def PlotAccuracy( corrects_history, val_corrects_history):\n",
        "  plt.style.use('seaborn-darkgrid')\n",
        "  plt.figure()\n",
        "  plt.plot(corrects_history, color = '#1ddb1d')\n",
        "  plt.plot(val_corrects_history, color = '#fcebfa')\n",
        "  plt.title('Model Accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch #')\n",
        "  plt.legend(['Training accuracy', 'Validation accuracy'], loc='lower right')\n",
        "  # plt.grid(axis = 'y', c = 'black', alpha = 0.2)\n",
        "  plt.grid(axis = 'x', c = 'black', alpha = 0.2)\n",
        "  plt.savefig(r'graphs\\vgg16_acc.png', dpi = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtSASbBYDERp"
      },
      "source": [
        "##############################\n",
        "#this function gets loss history and validation loss history and plots the models loss\n",
        "def PlotLoss(loss_history, val_loss_history):\n",
        "  plt.style.use('seaborn-darkgrid')\n",
        "  plt.figure()\n",
        "  plt.plot(loss_history, color = 'magenta')\n",
        "  plt.plot(val_loss_history, color = '#606060')\n",
        "  plt.title('Model Loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch #')\n",
        "  plt.legend(['Training loss', 'Validation loss'], loc='upper right')\n",
        "  plt.grid(axis = 'y', c = 'black', alpha = 0.2)\n",
        "  plt.grid(axis = 'x', c = 'black', alpha = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxMsNlI0CBvf"
      },
      "source": [
        "##############\n",
        "#this function rounds down the result\n",
        "def round_down(value, decimals):\n",
        "    factor = 1 / (10 ** decimals)\n",
        "    return (value // factor) * factor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "LpXcsJ8mDERl"
      },
      "source": [
        "#############\n",
        "#this function trains the model with the provided data, to predict if there is a tumor in the sample\n",
        "def training(\n",
        "  loss_history=[],\n",
        "  corrects_history=[],\n",
        "  val_loss_history=[],\n",
        "  val_corrects_history=[]):\n",
        "\n",
        "\n",
        "  val_loss_min = np.inf\n",
        "  for epoch in range(nepochs ): \n",
        "      \n",
        "      t0 = time.time()\n",
        "      running_loss=0.0\n",
        "      running_corrects=0.0\n",
        "      val_running_loss=0.0\n",
        "      val_running_corrects=0.0\n",
        "      \n",
        "      model.train()\n",
        "      for images,labels in train_loader:\n",
        "          #use gpu if possible\n",
        "          images=images.to(device)\n",
        "          labels=labels.to(device)\n",
        "\n",
        "          #update the output \n",
        "          outputs=model(images)\n",
        "          loss=criterion(outputs, labels)\n",
        "          \n",
        "          #step of training\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          \n",
        "          #calculation of results\n",
        "          running_loss+=loss.item()\n",
        "          _, preds=torch.max(outputs, 1)\n",
        "          running_corrects+=torch.sum(preds==labels.data)\n",
        "      \n",
        "      else:\n",
        "          #evaluation        \n",
        "          model.eval()\n",
        "          \n",
        "          with torch.no_grad():\n",
        "              #check with validation data\n",
        "              for val_images,val_labels, in validation_loader:\n",
        "                  #use gpu if possible\n",
        "                  val_images=val_images.to(device)\n",
        "                  val_labels=val_labels.to(device)\n",
        "\n",
        "                  #update the output\n",
        "                  val_outputs=model(val_images)\n",
        "                  val_loss=criterion(val_outputs, val_labels)\n",
        "                  \n",
        "                  #calculation of results without updating the model\n",
        "                  val_running_loss+=val_loss.item()\n",
        "                  _, val_preds=torch.max(val_outputs, 1)\n",
        "                  val_running_corrects+=torch.sum(val_preds==val_labels.data)\n",
        "      #insert training information for plotting\n",
        "      epoch_loss=running_loss/len(train_loader.dataset)\n",
        "      epoch_acc=running_corrects.float()/len(train_loader.dataset) \n",
        "      loss_history.append(epoch_loss)\n",
        "      corrects_history.append(epoch_acc)\n",
        "\n",
        "      #insert validation information for plotting\n",
        "      val_epoch_loss=val_running_loss/len(validation_loader.dataset)\n",
        "      val_epoch_acc=val_running_corrects.float()/len(validation_loader.dataset) \n",
        "      val_loss_history.append(val_epoch_loss)\n",
        "      val_corrects_history.append(val_epoch_acc)\n",
        "      \n",
        "      #setting checkpoint\n",
        "      checkpoint = {\n",
        "              'epoch': epoch + 1\n",
        "              ,'state_dict': model.state_dict()\n",
        "              ,'optimizer' : optimizer.state_dict()\n",
        "              ,'val_loss_min' : val_epoch_loss\n",
        "          }\n",
        "      \n",
        "      \n",
        "\n",
        "      print('epoch: ', (epoch + 1))\n",
        "\n",
        "      print('training loss: {:.4f}, acc: {:.4f}'.format(epoch_loss ,round_down(epoch_acc.item(),4)))\n",
        "      print('validation loss: {:.4f}, acc: {:.4f}'.format(val_epoch_loss, round_down(val_epoch_acc.item(),4)))\n",
        "      print('epoch time: {:.4f} seconds'.format(time.time() - t0))\n",
        "      #save checkpoint if validation loss is smaller than the minimal loss\n",
        "      if val_epoch_loss <= val_loss_min:\n",
        "          print('validation loss decreased from {:.4f} to {:.4f}, saving model...'.format(val_loss_min,        val_epoch_loss))\n",
        "          torch.save(checkpoint, r'checkpoint\\vgg16_lowest_val_loss_epoch_{}.pth'.format(epoch + 1))\n",
        "          val_loss_min = val_epoch_loss\n",
        "  return loss_history  ,val_loss_history ,corrects_history ,val_corrects_history;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgO2Cdbt6K9v"
      },
      "source": [
        "TEST provided by Zach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moPk5Ffcduyh"
      },
      "source": [
        "idx = np.arange(0, 30)\n",
        "\n",
        "test_yes = {}\n",
        "test_no = {}\n",
        "\n",
        "test_yes['test'] = Subset(dataset_yes_test, idx)\n",
        "test_set_yes = {x:DataLoader(test_yes[x],30, shuffle=True, num_workers=2) for x in ['test']}\n",
        "\n",
        "test_no['test'] = Subset(dataset_no_test, idx)\n",
        "test_set_no = {x:DataLoader(test_no[x],30, shuffle=True, num_workers=2) for x in ['test']}\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtl7bE--W-Z4"
      },
      "source": [
        "Set the values that your model uses for the case where a tumor exists or does not exist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kPgrJoAnqjp"
      },
      "source": [
        "predict_tumor = 1\n",
        "predict_no_tumor = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EijUPWV3bS5"
      },
      "source": [
        "def test(model):\n",
        "    model.eval()\n",
        "    corrects = 0\n",
        "\n",
        "    for inputs_yes, labels_yes in test_set_yes['test']:\n",
        "        #labels_yes += predict_tumor  #(didnt use because this line created labels of 2 and 0 and we used 1 and 0)\n",
        "        inputs_yes = inputs_yes.to(device)\n",
        "        labels_yes = labels_yes.to(device)\n",
        "\n",
        "    for inputs_no, labels_no in test_set_no['test']:\n",
        "        #labels_no += predict_no_tumor \n",
        "        inputs_no = inputs_no.to(device)\n",
        "        labels_no = labels_no.to(device)\n",
        "\n",
        "    inputs = torch.cat((inputs_yes, inputs_no), 0)\n",
        "    labels = torch.cat((labels_yes, labels_no), 0)\n",
        "    outputs = model(inputs)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    corrects += torch.sum(preds == labels.data)\n",
        "    acc = corrects.double() / 60\n",
        "    print('Test accuracy = ', acc)\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4BlaXNfeFPN"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  # run training model\n",
        "  loss_history  ,val_loss_history ,corrects_history ,val_corrects_history = training()\n",
        "\n",
        "  #plot graphs\n",
        "  PlotLossAccuracy( loss_history  ,val_loss_history ,corrects_history ,val_corrects_history)\n",
        "  PlotLoss(loss_history, val_loss_history)\n",
        "  PlotAccuracy( corrects_history, val_corrects_history)\n",
        "  \n",
        "  #test the model\n",
        "  test(model)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}